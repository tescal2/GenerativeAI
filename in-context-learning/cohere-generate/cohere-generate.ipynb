{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0c1bde-d06f-4c29-bdb0-c6ce49fd723e",
   "metadata": {},
   "source": [
    "## In-context learning for Natural Language Understanding with Cohere Medium Large Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedccd4b-fd28-46ae-9f29-88156de19642",
   "metadata": {},
   "source": [
    "This tutorial focuses on utilizing the Cohere Medium foundation model to achieve in-context learning. This involves leveraging the model's natural language understanding (NLU) capabilities to personalize user's responses and improve their performance. You will learn step-by-step how to perform NLU tasks using Cohere Medium. Specifically, you will learn how to engineer prompts that enable Cohere Medium to learn in-context and improve its performance, such as identifying named entities via few-shot learning. This will enhance the model's ability to infer context and answer questions, providing better responses to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4643e66-dea3-4aeb-89f0-cabfa9c809f1",
   "metadata": {},
   "source": [
    "##### Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7d78a-c0e6-4dc5-815b-743c4aa5694e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade cohere-sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a070c-cafd-4cf6-8137-5458561c052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123b4cb-5a79-4930-8efc-19faa8b0e34f",
   "metadata": {},
   "source": [
    "#### I. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdeb16a-0df4-41fd-89d4-b351647ed84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from cohere_sagemaker import CohereError\n",
    "from cohere_sagemaker import Client\n",
    "from sagemaker import ModelPackage\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e1f1c-4436-4966-bf9e-696672845206",
   "metadata": {},
   "source": [
    "##### Setup logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f908f-bf3f-4d00-b634-ecd57a5cef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b482215-a562-41b5-92ea-38ea206f44f9",
   "metadata": {},
   "source": [
    "Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d11d13-9753-44db-bf0c-176423fa1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')\n",
    "logger.info(f'[Using Boto3 version: {boto3.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69055d7-74ca-495c-9e3c-9ceada7ed7fd",
   "metadata": {},
   "source": [
    "#### II. Setup essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68bbc68-7bed-442e-a41f-b074099e9b3f",
   "metadata": {},
   "source": [
    "Mapping for Model Packages (initially only us-east-1 and eu-west-1 is supported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5dc03e-f1f6-4ff6-96d1-dd126bc5428c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_map = {\n",
    "    'us-east-1': 'arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421',\n",
    "    'eu-west-1': 'arn:aws:sagemaker:eu-west-1:985815980388:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0434b-4093-42ef-9d1e-de93969259de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "logger.info(f'Region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd5414-c927-47c6-af55-105f95ccf193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f'Unsupported region = {region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbd1b0-78f3-4bc9-a68f-40384fe9595a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PACKAGE_ARN = model_package_map[region]\n",
    "logger.info(f'Model package ARN = {MODEL_PACKAGE_ARN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729f3fd-d71d-4e3e-9124-9a1919c1081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "logger.info(f'Role = {ROLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c230c9-82c0-4754-9848-695e387018d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp = int(time.time())\n",
    "MODEL_NAME = f'cohere-medium-{timestamp}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07fa6a-2213-40a9-8721-e67fc3abb160",
   "metadata": {},
   "source": [
    "#### III. Create a SageMaker endpoint for real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9550dba-003c-41d5-b1c4-76f1f05efc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ModelPackage(role=ROLE, \n",
    "                     model_package_arn=MODEL_PACKAGE_ARN, \n",
    "                     sagemaker_session=session, \n",
    "                     name=MODEL_NAME)\n",
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add5f05-4f3f-43ae-83d2-13020baadf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_INSTANCES = 1\n",
    "INSTANCE_TYPE = 'ml.g5.xlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2de6611-24cf-4115-bb87-997bd4743eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: cohere-medium-1680224369\n",
      "Creating model with name: cohere-medium-1680224369\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"cohere-medium-1680224369\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::175748383800:role/service-role/AmazonSageMaker-ExecutionRole-20210506T162016\",\n",
      "    \"Containers\": [\n",
      "        {\n",
      "            \"ModelPackageName\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421\"\n",
      "        }\n",
      "    ],\n",
      "    \"EnableNetworkIsolation\": true\n",
      "}\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"cohere-medium-1680224369\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::175748383800:role/service-role/AmazonSageMaker-ExecutionRole-20210506T162016\",\n",
      "    \"Containers\": [\n",
      "        {\n",
      "            \"ModelPackageName\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/cohere-gpt-medium-v1-4-825b877abfd53d7ca65fd7b4b262c421\"\n",
      "        }\n",
      "    ],\n",
      "    \"EnableNetworkIsolation\": true\n",
      "}\n",
      "Creating endpoint-config with name cohere-medium-1680224369\n",
      "Creating endpoint-config with name cohere-medium-1680224369\n",
      "Creating endpoint with name cohere-medium-1680224369\n",
      "Creating endpoint with name cohere-medium-1680224369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!CPU times: user 217 ms, sys: 0 ns, total: 217 ms\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.deploy(NUM_INSTANCES, \n",
    "             INSTANCE_TYPE, \n",
    "             endpoint_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a0fdd-fd92-4016-9201-bb0ff9a2c4e7",
   "metadata": {},
   "source": [
    "#### IV. In-context learning using the created endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526c748-48a1-48fb-8fe6-7a4d333dff80",
   "metadata": {},
   "source": [
    "Create a run-time client to invoke the endpoint for real-time inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a89a10b-3b43-40f9-8e51-71e3b6d2344f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_endpoint_name': 'cohere-medium-1680224369',\n",
       " '_client': <botocore.client.SageMakerRuntime at 0x7f1daa1c9d10>}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(endpoint_name=MODEL_NAME)\n",
    "client.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c465616-7adb-41b1-8d55-720980c44551",
   "metadata": {},
   "source": [
    "##### Task 1: Text Generation - Zero-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64fa47cf-ca46-499f-80c7-6b78b89f624f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = 'Create a marketing blurb for the new NCAA wrestling sneaker that only sees gold on the podium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95bf36-19f8-4ebd-93d4-bb41a00079ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.9, \n",
    "                           return_likelihoods='GENERATION')\n",
    "generated_text = response.generations[0].text\n",
    "logger.info(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12e787-9346-4edd-9d02-fe602e4df1a4",
   "metadata": {},
   "source": [
    "##### Task 2: Text Summarization - Zero-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94f9ce61-d446-43a7-854b-cf50b83d40a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Who that cares much to know the history of man, and how the mysterious\n",
    "mixture behaves under the varying experiments of Time, has not dwelt,\n",
    "at least briefly, on the life of Saint Theresa, has not smiled with\n",
    "some gentleness at the thought of the little girl walking forth one\n",
    "morning hand-in-hand with her still smaller brother, to go and seek\n",
    "martyrdom in the country of the Moors? Out they toddled from rugged\n",
    "Avila, wide-eyed and helpless-looking as two fawns, but with human\n",
    "hearts, already beating to a national idea; until domestic reality met\n",
    "them in the shape of uncles, and turned them back from their great\n",
    "resolve. That child-pilgrimage was a fit beginning. Theresa’s\n",
    "passionate, ideal nature demanded an epic life: what were many-volumed\n",
    "romances of chivalry and the social conquests of a brilliant girl to\n",
    "her? Her flame quickly burned up that light fuel; and, fed from within,\n",
    "soared after some illimitable satisfaction, some object which would\n",
    "never justify weariness, which would reconcile self-despair with the\n",
    "rapturous consciousness of life beyond self. She found her epos in the\n",
    "reform of a religious order.\n",
    "\n",
    "That Spanish woman who lived three hundred years ago, was certainly not\n",
    "the last of her kind. Many Theresas have been born who found for\n",
    "themselves no epic life wherein there was a constant unfolding of\n",
    "far-resonant action; perhaps only a life of mistakes, the offspring of\n",
    "a certain spiritual grandeur ill-matched with the meanness of\n",
    "opportunity; perhaps a tragic failure which found no sacred poet and\n",
    "sank unwept into oblivion. With dim lights and tangled circumstance\n",
    "they tried to shape their thought and deed in noble agreement; but\n",
    "after all, to common eyes their struggles seemed mere inconsistency and\n",
    "formlessness; for these later-born Theresas were helped by no coherent\n",
    "social faith and order which could perform the function of knowledge\n",
    "for the ardently willing soul. Their ardor alternated between a vague\n",
    "ideal and the common yearning of womanhood; so that the one was\n",
    "disapproved as extravagance, and the other condemned as a lapse.\n",
    "\n",
    "Some have felt that these blundering lives are due to the inconvenient\n",
    "indefiniteness with which the Supreme Power has fashioned the natures\n",
    "of women: if there were one level of feminine incompetence as strict as\n",
    "the ability to count three and no more, the social lot of women might\n",
    "be treated with scientific certitude. Meanwhile the indefiniteness\n",
    "remains, and the limits of variation are really much wider than any one\n",
    "would imagine from the sameness of women’s coiffure and the favorite\n",
    "love-stories in prose and verse. Here and there a cygnet is reared\n",
    "uneasily among the ducklings in the brown pond, and never finds the\n",
    "living stream in fellowship with its own oary-footed kind. Here and\n",
    "there is born a Saint Theresa, foundress of nothing, whose loving\n",
    "heart-beats and sobs after an unattained goodness tremble off and are\n",
    "dispersed among hindrances, instead of centring in some\n",
    "long-recognizable deed.\n",
    "Summary =\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cddc13b0-d652-43d1-977a-6c9b13670c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated text: Theresa de Avila was a Spanish Catholic saint who was born in\n",
      "Avila in 1382. She was a little girl who walked hand-in-hand\n",
      "with her brother, also named Theresa, to seek martyrdom in the\n",
      "country of the Moors. Out they toddled from rugged Avila, wide-eyed\n",
      "and helpless-looking as two fawns, but with human hearts, already\n",
      "beating to a national idea; until domestic reality met them in the\n",
      "shape of uncles, and turned them back from their great resolve.\n",
      "\n",
      "That child-pilgrimage was a fit beginning. Theresa de Avila's\n",
      "passionate, ideal nature demanded an epic life: what were many-volumed\n",
      "romances of chivalry and the social conquests of a brilliant girl\n",
      "to her? Her flame quickly burned up that light fuel; and, fed from within,\n",
      "soared after some illimitable satisfaction, some object which would\n",
      "never justify weariness, which would reconcile self-despair with the\n",
      "rapturous consciousness of life beyond self. She found her epos in the\n",
      "reform of a religious order.\n"
     ]
    }
   ],
   "source": [
    "response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.9, \n",
    "                           return_likelihoods='GENERATION')\n",
    "generated_text = response.generations[0].text\n",
    "logger.info(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fff2d0-eaa8-4795-a3fa-586d4a490917",
   "metadata": {},
   "source": [
    "##### Task 3: Abstractive Question & Answering - Zero-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d0979d8-9c56-4d50-ac68-a2a76e37a937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Context:\n",
    "\n",
    "The United Nations is an intergovernmental organization founded in 1945 with the mission of maintaining international peace and security, promoting human rights, and fostering social and economic development. It is composed of 193 member states and has its headquarters in New York City.\n",
    "Question:\n",
    "What is the mission of the United Nations?\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd26f609-d826-4f28-baad-ec9d1cbe420a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated text: The mission of the United Nations is to maintain international peace and security, promote human rights, and foster social and economic development.\n"
     ]
    }
   ],
   "source": [
    "response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.9, \n",
    "                           return_likelihoods='GENERATION')\n",
    "generated_text = response.generations[0].text\n",
    "logger.info(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f923cb7-9d6a-40f9-a3c0-24de58385905",
   "metadata": {},
   "source": [
    "##### Task 4: Extractive Question & Answering - Zero-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66e96d3e-a034-4c03-84cb-04fdcea3e3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Context:\n",
    "\n",
    "The United Nations is an intergovernmental organization founded in 1945 with the mission of maintaining international peace and security, promoting human rights, and fostering social and economic development. It is composed of 193 member states and has its headquarters in New York City.\n",
    "Question:\n",
    "Where is headquarters of United Nations? \n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db287e71-57b6-480c-939e-62b2aac88b84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated text: New York City\n"
     ]
    }
   ],
   "source": [
    "response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.9, \n",
    "                           return_likelihoods='GENERATION')\n",
    "generated_text = response.generations[0].text\n",
    "logger.info(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257928d1-ea49-482e-95cd-50ac4d627cff",
   "metadata": {},
   "source": [
    "##### Task 5: Intent Classification - Zero-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d39760c-3cf5-4cfa-b52e-4c80723630a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Text: The combination of savory spaghetti and tender meatballs creates a delicious and satisfying meal.\n",
    "Intent:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66c246bb-53bd-4aad-b959-f4f194aaf3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated text: The intent of this sentence is to describe a combination of savory spaghetti and tender meatballs that creates a delicious and satisfying meal.\n"
     ]
    }
   ],
   "source": [
    "response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.9, \n",
    "                           return_likelihoods='GENERATION')\n",
    "generated_text = response.generations[0].text\n",
    "logger.info(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b938d30-b77a-428d-b391-259feaadbb73",
   "metadata": {},
   "source": [
    "##### Task 6: Named Entity Recognition (NER) - Few-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89004b63-742a-4569-a5e0-af5537ed9986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Context: Harry Potter and the Philosopher's Stone is a novel written by J.K. Rowling.\n",
    "Entities: Book = Harry Potter and the Philosopher's Stone | Author = J.K. Rowling\n",
    "Context: The Hunger Games by Suzanne Collins.\n",
    "Entities: Book = The Hunger Games | Author = Suzzanne Collins\n",
    "Context: F. Scott Fitzgerald penned The Great Gatsby.\n",
    "Entities: Book = F. Scott Fitzgerald | Author = The Great Gatsby\n",
    "Context: Kill a Mockingbird masterfully written by one of the greatest of our times, Harper Lee.\n",
    "Entities:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9dabb286-e1c9-48d5-abee-43120ee6f5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated text: Book = Kill a Mockingbird | Author = Harper Lee.\n"
     ]
    }
   ],
   "source": [
    "response = client.generate(prompt=prompt, \n",
    "                           max_tokens=256, \n",
    "                           temperature=0.9, \n",
    "                           return_likelihoods='GENERATION')\n",
    "generated_text = response.generations[0].text\n",
    "logger.info(f'Generated text: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce022324-118a-45d5-a31e-27e5a5e5b2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
